{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c2e0c2",
   "metadata": {},
   "source": [
    "# Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a955e",
   "metadata": {},
   "source": [
    "### Leemos los ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c4901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(df):\n",
    "    from pyspark.sql.functions import regexp_extract, col\n",
    "    from pyspark.sql.types import StringType, BooleanType, IntegerType\n",
    "    df_prima = df.select(col(\"Id\").cast(IntegerType()), \n",
    "                      \"Name\", \n",
    "                      \"Authors\", \n",
    "                      \"ISBN\", \n",
    "                      col(\"pagesNumber\").cast(IntegerType()),\n",
    "                      \"Language\", \n",
    "                      \"Publisher\", \n",
    "                      col(\"PublishDay\").cast(IntegerType()), \n",
    "                      col(\"PublishMonth\").cast(IntegerType()), \n",
    "                      col(\"PublishYear\").cast(IntegerType()), \n",
    "                      \"Rating\",\n",
    "                      regexp_extract(\"RatingDist1\", '1:(\\d*)', 1).alias(\"RatingDist1\").cast(IntegerType()), \n",
    "                      regexp_extract(\"RatingDist2\", '2:(\\d*)', 1).alias(\"RatingDist2\").cast(IntegerType()), \n",
    "                      regexp_extract(\"RatingDist3\", '3:(\\d*)', 1).alias(\"RatingDist3\").cast(IntegerType()), \n",
    "                      regexp_extract(\"RatingDist4\", '4:(\\d*)', 1).alias(\"RatingDist4\").cast(IntegerType()), \n",
    "                      regexp_extract(\"RatingDist5\", '5:(\\d*)', 1).alias(\"RatingDist5\").cast(IntegerType()),\n",
    "                      regexp_extract(\"RatingDistTotal\", 'total:(\\d*)', 1).alias(\"RatingDistTotal\").cast(IntegerType()),\n",
    "                      col(\"CountsOfReview\").cast(IntegerType())\n",
    "                     )\n",
    "    return df_prima\n",
    "\n",
    "def cambio_col(df,col1, col2, nombre1, nombre2):\n",
    "    from pyspark.sql.functions import col\n",
    "    df = df.withColumn(\"la1\", col(col2))\n",
    "    df = df.withColumn(\"la2\", col(col1))\n",
    "    df = df.drop(col1)\n",
    "    df = df.drop(col2)\n",
    "    df = df.withColumn(nombre1, col(\"la1\"))\n",
    "    df = df.withColumn(nombre2, col(\"la2\"))\n",
    "    df = df.drop(\"la1\")\n",
    "    df = df.drop(\"la2\")\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def dicc_df(archivos1, archivos2, ruta):\n",
    "    dataframes = dict()\n",
    "    for i in range(len(archivos1)):\n",
    "        if i == 0:\n",
    "            ruta_i = ruta+'\\\\'+'book' + str(archivos1[i]) + '-'+str(archivos2[i])+'k'+'.csv'\n",
    "        else:\n",
    "            ruta_i = ruta+'\\\\'+'book' + str(archivos1[i])+'k' + '-'+str(archivos2[i])+'k'+'.csv'\n",
    "        #print(ruta_i)\n",
    "        name = 'archivo'+'_'+str(i+1)\n",
    "        arch_i = spark.read.csv(ruta_i, \n",
    "                    header=True, \n",
    "                    sep=',', \n",
    "                    quote=\"\\\"\", \n",
    "                    escape=\"\\\"\", \n",
    "                    ignoreTrailingWhiteSpace = True,\n",
    "                    multiLine = True)\n",
    "        #print(arch_i.count())\n",
    "        arch_i_col = cambio_col(arch_i, \"PublishDay\", \"PublishMonth\", \"PublishDay\", \"PublishMonth\")\n",
    "        arch_i_pr = regex(arch_i_col)\n",
    "        #print(arch_i_pr.show(3))\n",
    "        dataframes[name] = arch_i_pr\n",
    "    return dataframes\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "def union_df(dataframes, ar):\n",
    "    i=1\n",
    "    for nombre, dataframe in dataframes.items():\n",
    "        #print(nombre)\n",
    "        if nombre != 'archivo_1':\n",
    "            i+=1\n",
    "            union = ar.union(dataframe)\n",
    "            ar = union\n",
    "    return i, ar\n",
    "\n",
    "def nombre_ficheros():\n",
    "    flag = False\n",
    "    primero = [1]\n",
    "    a = list(range(100, 2100, 100))\n",
    "    primero.extend(a)\n",
    "    primero.append(3000)\n",
    "    primero.append(4000)\n",
    "    segundo = list(range(100,2000, 100))\n",
    "    for i in list(range(2000, 6000, 1000)):\n",
    "        segundo.append(i)\n",
    "    if len(primero) == len(segundo):\n",
    "        flag = True\n",
    "    return primero, segundo, flag\n",
    "\n",
    "def nulos(df):\n",
    "    from pyspark.sql.functions import col\n",
    "    for columna in df.columns:\n",
    "        print(columna)\n",
    "        print(df.select(columna).where((col(columna) == '') | (col(columna).isNull())).count())\n",
    "        print('\\n')\n",
    "\n",
    "def save_csv(df, ruta):\n",
    "    df.write.format(\"dataframe.csv\").save(ruta, header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5bc412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han unido 23 datafames\n",
      "Hay un total de 1850310 filas\n"
     ]
    }
   ],
   "source": [
    "pr, se, flag = nombre_ficheros()\n",
    "if flag:\n",
    "    ruta = 'C:\\\\Users\\\\nora.hafidi\\\\Desktop\\\\Big Data\\\\UserRating\\\\archive'\n",
    "    dfs = dicc_df(pr, se, ruta)\n",
    "    ar = dfs['archivo_1']\n",
    "    num, df = union_df(dfs, ar)\n",
    "    print(\"Se han unido \" + str(int(num)) + \" datafames\")\n",
    "    print(\"Hay un total de \"+str(df.count())+\" filas\")\n",
    "    \n",
    "else: print('Hay error el los nombres de los ficheros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "52ea43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------+----------+-----------+--------+---------------+----------+------------+-----------+------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+\n",
      "| Id|                Name|     Authors|      ISBN|pagesNumber|Language|      Publisher|PublishDay|PublishMonth|PublishYear|Rating|RatingDist1|RatingDist2|RatingDist3|RatingDist4|RatingDist5|RatingDistTotal|CountsOfReview|\n",
      "+---+--------------------+------------+----------+-----------+--------+---------------+----------+------------+-----------+------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+\n",
      "|  1|Harry Potter and ...|J.K. Rowling|      null|        652|     eng|Scholastic Inc.|        16|           9|       2006|  4.57|       9896|      25317|     159960|     556485|    1546466|        2298124|         28062|\n",
      "|  2|Harry Potter and ...|J.K. Rowling|0439358078|        870|     eng|Scholastic Inc.|         1|           9|       2004|   4.5|      12455|      37005|     211781|     604283|    1493113|        2358637|         29770|\n",
      "|  3|Harry Potter and ...|J.K. Rowling|      null|        309|     eng| Scholastic Inc|         1|          11|       2003|  4.47|     108202|     130310|     567458|    1513191|    4268227|        6587388|         75911|\n",
      "+---+--------------------+------------+----------+-----------+--------+---------------+----------+------------+-----------+------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44339e01",
   "metadata": {},
   "source": [
    "### Contamos los nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af6451ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n",
      "0\n",
      "\n",
      "\n",
      "Name\n",
      "0\n",
      "\n",
      "\n",
      "Authors\n",
      "0\n",
      "\n",
      "\n",
      "ISBN\n",
      "5923\n",
      "\n",
      "\n",
      "pagesNumber\n",
      "0\n",
      "\n",
      "\n",
      "Language\n",
      "1598488\n",
      "\n",
      "\n",
      "Publisher\n",
      "17824\n",
      "\n",
      "\n",
      "PublishDay\n",
      "0\n",
      "\n",
      "\n",
      "PublishMonth\n",
      "0\n",
      "\n",
      "\n",
      "PublishYear\n",
      "0\n",
      "\n",
      "\n",
      "Rating\n",
      "0\n",
      "\n",
      "\n",
      "RatingDist1\n",
      "0\n",
      "\n",
      "\n",
      "RatingDist2\n",
      "0\n",
      "\n",
      "\n",
      "RatingDist3\n",
      "0\n",
      "\n",
      "\n",
      "RatingDist4\n",
      "0\n",
      "\n",
      "\n",
      "RatingDist5\n",
      "1\n",
      "\n",
      "\n",
      "RatingDistTotal\n",
      "1\n",
      "\n",
      "\n",
      "CountsOfReview\n",
      "0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "nulos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "30efc26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Id,IntegerType,true),StructField(Name,StringType,true),StructField(Authors,StringType,true),StructField(ISBN,StringType,true),StructField(pagesNumber,IntegerType,true),StructField(Language,StringType,true),StructField(Publisher,StringType,true),StructField(PublishDay,IntegerType,true),StructField(PublishMonth,IntegerType,true),StructField(PublishYear,IntegerType,true),StructField(Rating,StringType,true),StructField(RatingDist1,IntegerType,true),StructField(RatingDist2,IntegerType,true),StructField(RatingDist3,IntegerType,true),StructField(RatingDist4,IntegerType,true),StructField(RatingDist5,IntegerType,true),StructField(RatingDistTotal,IntegerType,true),StructField(CountsOfReview,IntegerType,true)))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04776b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'Name',\n",
       " 'Authors',\n",
       " 'ISBN',\n",
       " 'pagesNumber',\n",
       " 'Language',\n",
       " 'Publisher',\n",
       " 'PublishDay',\n",
       " 'PublishMonth',\n",
       " 'PublishYear',\n",
       " 'Rating',\n",
       " 'RatingDist1',\n",
       " 'RatingDist2',\n",
       " 'RatingDist3',\n",
       " 'RatingDist4',\n",
       " 'RatingDist5',\n",
       " 'RatingDistTotal',\n",
       " 'CountsOfReview']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab398b0",
   "metadata": {},
   "source": [
    "### Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c938457",
   "metadata": {},
   "source": [
    "1. Rating promedio de todos los libros\n",
    "2. Rating promedio de los libros por autor\n",
    "3. Rating promedio de los libros por Publisher\n",
    "4. Número promedio de páginas de todos los libros\n",
    "5. Número promedio de páginas de todos los libros por autor\n",
    "6. Número promedio de páginas de todos los libros por Publisher\n",
    "7. Número promedio de libros publicados por autor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f041abb2",
   "metadata": {},
   "source": [
    "**1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3ecb4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  media|\n",
      "+-------+\n",
      "|4079.37|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    "    .select(round(F.avg(\"RatingDistTotal\"), 2).alias(\"media\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03452ff7",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b0d2a",
   "metadata": {},
   "source": [
    "**2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "03976f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|           Authors|RankingMedio|\n",
      "+------------------+------------+\n",
      "|        Harper Lee|  4379386.33|\n",
      "|      J.K. Rowling|  2980838.63|\n",
      "|           Frank a|   2696635.0|\n",
      "|   Stephenie Meyer|  2221830.85|\n",
      "|  Kathryn Stockett|   2176064.0|\n",
      "|        Anne Frank|  2116704.94|\n",
      "|   Khaled Hosseini|  1879581.96|\n",
      "|     Arthur Golden|  1674126.95|\n",
      "|         Dan Brown|  1569989.69|\n",
      "|     Stieg Larsson|  1479435.57|\n",
      "|     J.D. Salinger|  1294132.54|\n",
      "|      Alice Sebold|  1280483.88|\n",
      "|   Cassandra Clare|  1267328.63|\n",
      "|Audrey Niffenegger|   1247628.1|\n",
      "|   Stephen Chbosky|   1228365.0|\n",
      "|     George Orwell|   962633.51|\n",
      "|      Markus Zusak|   959495.37|\n",
      "|      Emily Brontë|   894090.67|\n",
      "|            Homere|    853888.0|\n",
      "|        Sara Gruen|   803369.64|\n",
      "+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    "    .groupBy(\"Authors\")\n",
    "    .agg(round(F.avg(\"RatingDistTotal\"), 2).alias(\"RankingMedio\"))\n",
    "    .orderBy(\"RankingMedio\", ascending=False)\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da58700",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac91a1",
   "metadata": {},
   "source": [
    "**3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8ac2e55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           Publisher|RankingMedio|\n",
      "+--------------------+------------+\n",
      "|         Bloomsburry|   6788211.0|\n",
      "|De Harmonie Amste...|   6765897.0|\n",
      "|Raincoast Book Di...|   6742740.0|\n",
      "|   Εκδόσεις Ψυχογιός|   4919788.0|\n",
      "|Mañjula Pabliśiṅg...|   4604856.0|\n",
      "|              Росмэн|   4553845.5|\n",
      "|            Petersen|   4347616.0|\n",
      "|Arthur A. Levine ...|   3886252.0|\n",
      "|       Media Rodzina|  3755142.29|\n",
      "|Chuoukouron Shins...|   3680023.0|\n",
      "|      Mediasat Group|   3637798.0|\n",
      "|              静山社|  3617272.88|\n",
      "|               Tiden|   3472393.0|\n",
      "|          Intrínseca|   3403592.0|\n",
      "|Bloomsbury Childrens|   3300082.5|\n",
      "|      人民文学出版社|  3194597.83|\n",
      "| New America Library|   3147152.0|\n",
      "|Houghton Brace Jo...|   3011308.0|\n",
      "|Secker & Warburg ...|   2987256.0|\n",
      "|      Archeion Press|  2969239.67|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    "    .groupBy(\"Publisher\")\n",
    "    .agg(round(F.avg(\"RatingDistTotal\"),2).alias(\"RankingMedio\"))\n",
    "    .orderBy(\"RankingMedio\", ascending=False)\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65bc9e0",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b991cdf",
   "metadata": {},
   "source": [
    "**4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ece2431c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|MediaPaginas|\n",
      "+------------+\n",
      "|      276.55|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    "    .select(round(F.avg(\"pagesNumber\"), 2).alias(\"MediaPaginas\"))\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf46128",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca7d00",
   "metadata": {},
   "source": [
    "**5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7335895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|             Authors|MediaPaginas|\n",
      "+--------------------+------------+\n",
      "|       Sandy Redburn|   1807321.6|\n",
      "|         A.B. Murphy|   751507.33|\n",
      "|        John B. Hare|    500000.0|\n",
      "|Logos Research Sy...|    100000.0|\n",
      "|Progressive Manag...|    35428.44|\n",
      "|     Timothy McVeigh|     33133.0|\n",
      "|   Robert H. Wozniak|     22100.0|\n",
      "|Veterans Affairs ...|     16153.0|\n",
      "|World Spaceflight...|    13942.33|\n",
      "|         Keith Crook|      9999.0|\n",
      "|             K. Muse|      9998.0|\n",
      "|       Patrick Burns|      9998.0|\n",
      "|         John Elstad|      9998.0|\n",
      "|     Douglas    Dunn|      9998.0|\n",
      "|        John Philcox|      9998.0|\n",
      "|            Joe Mayo|      9998.0|\n",
      "|  Albert J. Saganich|      9998.0|\n",
      "|      Alice Rischert|      9998.0|\n",
      "|Marian C. Merrill...|      9998.0|\n",
      "|      Derbish Braber|      9998.0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    "    .groupBy(\"Authors\")\n",
    "    .agg(round(F.avg(\"pagesNumber\"), 2).alias(\"MediaPaginas\"))\n",
    "    .orderBy(\"MediaPaginas\", ascending=False)\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "39cca428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|             Authors|MediaPaginas|\n",
      "+--------------------+------------+\n",
      "|       Sandy Redburn|     9036608|\n",
      "|           Anonymous|     2314273|\n",
      "|         A.B. Murphy|     2254522|\n",
      "|             Unknown|      741425|\n",
      "|Progressive Manag...|      566855|\n",
      "|        John B. Hare|      500000|\n",
      "| William Shakespeare|      420507|\n",
      "|Fodor's Travel Pu...|      293590|\n",
      "|        Stephen King|      290827|\n",
      "|     U.S. Government|      250964|\n",
      "|        Nora Roberts|      236668|\n",
      "|     Charles Dickens|      224916|\n",
      "|Microsoft Corpora...|      206295|\n",
      "|     Agatha Christie|      201075|\n",
      "|Cram101 Textbook ...|      200778|\n",
      "|          Mark Twain|      186553|\n",
      "|        Isaac Asimov|      181400|\n",
      "|National Research...|      181318|\n",
      "|             Various|      176426|\n",
      "|     Francine Pascal|      160393|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    "    .groupBy(\"Authors\")\n",
    "    .agg(F.sum(\"pagesNumber\").alias(\"MediaPaginas\"))\n",
    "    .orderBy(\"MediaPaginas\", ascending=False)\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1baafc",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bd623",
   "metadata": {},
   "source": [
    "**6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c4253259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|           Publisher|MediaPaginas|\n",
      "+--------------------+------------+\n",
      "|Crafty Secrets Pu...|   1807321.6|\n",
      "|    Sacred-texts.com|    500000.0|\n",
      "|Department of Rus...|   322128.57|\n",
      "|Logos Research Sy...|    100000.0|\n",
      "|Encyclopedia Brit...|     32642.0|\n",
      "|Progressive Manag...|    19106.36|\n",
      "|Still Waters Revi...|    10080.14|\n",
      "|P. Shalom Publica...|      8539.0|\n",
      "|Hendrickson Publi...|      6448.0|\n",
      "|            IEEE/EMB|      6000.0|\n",
      "|Research Applicat...|      5856.0|\n",
      "|   Hendrickson Publ.|      5808.0|\n",
      "|          Childcraft|      5760.0|\n",
      "|Jnanada Prakashan...|      5404.0|\n",
      "|   Páginas de espuma|      5000.0|\n",
      "|  Sigma Aldrich Corp|      4866.0|\n",
      "| World-Mysteries.com|      4710.0|\n",
      "|E B S C O Industr...|      4119.0|\n",
      "|Apple Pie Publish...|      4000.0|\n",
      "|     Edition Synapse|      3682.0|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df\n",
    "    .groupBy(\"Publisher\")\n",
    "    .agg(round(F.avg(\"pagesNumber\"), 2).alias(\"MediaPaginas\"))\n",
    "    .orderBy(\"MediaPaginas\", ascending=False)\n",
    "    .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091da218",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7538017",
   "metadata": {},
   "source": [
    "**7.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "127cfa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|             Authors|count|\n",
      "+--------------------+-----+\n",
      "|           Anonymous| 2894|\n",
      "|             Unknown| 2029|\n",
      "| William Shakespeare| 1373|\n",
      "|     Francine Pascal|  930|\n",
      "|     Agatha Christie|  885|\n",
      "|National Research...|  884|\n",
      "|Cram101 Textbook ...|  876|\n",
      "|Fodor's Travel Pu...|  858|\n",
      "|        Harold Bloom|  773|\n",
      "|             Various|  739|\n",
      "|        Isaac Asimov|  698|\n",
      "|        Nora Roberts|  647|\n",
      "|       Carolyn Keene|  647|\n",
      "|        Stephen King|  624|\n",
      "|          R.L. Stine|  620|\n",
      "| Walt Disney Company|  593|\n",
      "|Hal Leonard Publi...|  588|\n",
      "|          NOT A BOOK|  562|\n",
      "|          Mark Twain|  526|\n",
      "|       Ann M. Martin|  514|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    "     .groupBy(\"Authors\")\n",
    "     .count()\n",
    "     .orderBy(\"count\", ascending=False)\n",
    "     .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15e8e1",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e72d9",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7008222",
   "metadata": {},
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d4ead",
   "metadata": {},
   "source": [
    "### Leemos los ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c39d502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1000, 2000, 3000, 4000, 5000, 6000]\n",
      "[1000, 2000, 3000, 4000, 5000, 6000, 11000]\n"
     ]
    }
   ],
   "source": [
    "uno = list(range(0,7000,1000))\n",
    "dos = list(range(1000,7000,1000))\n",
    "dos.append(11000)\n",
    "print(uno)\n",
    "print(dos)\n",
    "ruta_r = 'C:\\\\Users\\\\nora.hafidi\\\\Desktop\\\\Big Data\\\\UserRating\\\\archive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ecc5d82",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "+---+--------------------+---------------+\n",
      "| ID|                Name|         Rating|\n",
      "+---+--------------------+---------------+\n",
      "|  1|Agile Web Develop...| it was amazing|\n",
      "|  1|The Restaurant at...| it was amazing|\n",
      "|  1|          Siddhartha| it was amazing|\n",
      "|  1|The Clock of the ...|really liked it|\n",
      "|  1|Ready Player One ...|really liked it|\n",
      "|  1|The Hunger Games ...| it was amazing|\n",
      "|  1|The Clue in the E...| it was amazing|\n",
      "|  1|The Authoritative...| it was amazing|\n",
      "|  1|The Clue of the B...| it was amazing|\n",
      "|  1|The Clue of the H...| it was amazing|\n",
      "|  1|The Clue of the S...| it was amazing|\n",
      "|  1|The Return of the...| it was amazing|\n",
      "|  1|The Name of the Rose|       liked it|\n",
      "|  1|Blue Mars (Mars T...|       liked it|\n",
      "|  1|Give and Take: A ...| it was amazing|\n",
      "|  1|Mindset: The New ...|really liked it|\n",
      "|  1|Bad Blood: Secret...|really liked it|\n",
      "|  1|Dark Apprentice (...|       liked it|\n",
      "|  1|A Short History o...| it was amazing|\n",
      "|  1|The Mystery of th...| it was amazing|\n",
      "+---+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "2\n",
      "+----+------+--------------------+\n",
      "|  ID|  Name|              Rating|\n",
      "+----+------+--------------------+\n",
      "|1000|Rating|This user doesn't...|\n",
      "|1001|Rating|This user doesn't...|\n",
      "|1002|Rating|This user doesn't...|\n",
      "|1003|Rating|This user doesn't...|\n",
      "|1005|Rating|This user doesn't...|\n",
      "|1010|Rating|This user doesn't...|\n",
      "|1011|Rating|This user doesn't...|\n",
      "|1012|Rating|This user doesn't...|\n",
      "|1019|Rating|This user doesn't...|\n",
      "|1022|Rating|This user doesn't...|\n",
      "|1027|Rating|This user doesn't...|\n",
      "|1028|Rating|This user doesn't...|\n",
      "|1031|Rating|This user doesn't...|\n",
      "|1032|Rating|This user doesn't...|\n",
      "|1033|Rating|This user doesn't...|\n",
      "|1034|Rating|This user doesn't...|\n",
      "|1035|Rating|This user doesn't...|\n",
      "|1036|Rating|This user doesn't...|\n",
      "|1038|Rating|This user doesn't...|\n",
      "|1039|Rating|This user doesn't...|\n",
      "+----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "3\n",
      "+----+------+--------------------+\n",
      "|  ID|  Name|              Rating|\n",
      "+----+------+--------------------+\n",
      "|2098|Rating|This user doesn't...|\n",
      "|2099|Rating|This user doesn't...|\n",
      "|2103|Rating|This user doesn't...|\n",
      "|2105|Rating|This user doesn't...|\n",
      "|2106|Rating|This user doesn't...|\n",
      "|2108|Rating|This user doesn't...|\n",
      "|2109|Rating|This user doesn't...|\n",
      "|2110|Rating|This user doesn't...|\n",
      "|2113|Rating|This user doesn't...|\n",
      "|2116|Rating|This user doesn't...|\n",
      "|2117|Rating|This user doesn't...|\n",
      "|2118|Rating|This user doesn't...|\n",
      "|2119|Rating|This user doesn't...|\n",
      "|2121|Rating|This user doesn't...|\n",
      "|2122|Rating|This user doesn't...|\n",
      "|2123|Rating|This user doesn't...|\n",
      "|2124|Rating|This user doesn't...|\n",
      "|2130|Rating|This user doesn't...|\n",
      "|2132|Rating|This user doesn't...|\n",
      "|2133|Rating|This user doesn't...|\n",
      "+----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "4\n",
      "+----+------+--------------------+\n",
      "|  ID|  Name|              Rating|\n",
      "+----+------+--------------------+\n",
      "|3182|Rating|This user doesn't...|\n",
      "|3183|Rating|This user doesn't...|\n",
      "|3187|Rating|This user doesn't...|\n",
      "|3188|Rating|This user doesn't...|\n",
      "|3191|Rating|This user doesn't...|\n",
      "|3193|Rating|This user doesn't...|\n",
      "|3194|Rating|This user doesn't...|\n",
      "|3196|Rating|This user doesn't...|\n",
      "|3204|Rating|This user doesn't...|\n",
      "|3205|Rating|This user doesn't...|\n",
      "|3215|Rating|This user doesn't...|\n",
      "|3217|Rating|This user doesn't...|\n",
      "|3218|Rating|This user doesn't...|\n",
      "|3221|Rating|This user doesn't...|\n",
      "|3231|Rating|This user doesn't...|\n",
      "|3233|Rating|This user doesn't...|\n",
      "|3234|Rating|This user doesn't...|\n",
      "|3237|Rating|This user doesn't...|\n",
      "|3242|Rating|This user doesn't...|\n",
      "|3243|Rating|This user doesn't...|\n",
      "+----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "5\n",
      "+----+------+--------------------+\n",
      "|  ID|  Name|              Rating|\n",
      "+----+------+--------------------+\n",
      "|4291|Rating|This user doesn't...|\n",
      "|4292|Rating|This user doesn't...|\n",
      "|4297|Rating|This user doesn't...|\n",
      "|4298|Rating|This user doesn't...|\n",
      "|4299|Rating|This user doesn't...|\n",
      "|4300|Rating|This user doesn't...|\n",
      "|4302|Rating|This user doesn't...|\n",
      "|4303|Rating|This user doesn't...|\n",
      "|4305|Rating|This user doesn't...|\n",
      "|4307|Rating|This user doesn't...|\n",
      "|4313|Rating|This user doesn't...|\n",
      "|4318|Rating|This user doesn't...|\n",
      "|4322|Rating|This user doesn't...|\n",
      "|4324|Rating|This user doesn't...|\n",
      "|4325|Rating|This user doesn't...|\n",
      "|4330|Rating|This user doesn't...|\n",
      "|4335|Rating|This user doesn't...|\n",
      "|4344|Rating|This user doesn't...|\n",
      "|4345|Rating|This user doesn't...|\n",
      "|4348|Rating|This user doesn't...|\n",
      "+----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "6\n",
      "+----+------+--------------------+\n",
      "|  ID|  Name|              Rating|\n",
      "+----+------+--------------------+\n",
      "|5410|Rating|This user doesn't...|\n",
      "|5411|Rating|This user doesn't...|\n",
      "|5412|Rating|This user doesn't...|\n",
      "|5416|Rating|This user doesn't...|\n",
      "|5417|Rating|This user doesn't...|\n",
      "|5419|Rating|This user doesn't...|\n",
      "|5420|Rating|This user doesn't...|\n",
      "|5421|Rating|This user doesn't...|\n",
      "|5424|Rating|This user doesn't...|\n",
      "|5425|Rating|This user doesn't...|\n",
      "|5427|Rating|This user doesn't...|\n",
      "|5428|Rating|This user doesn't...|\n",
      "|5435|Rating|This user doesn't...|\n",
      "|5438|Rating|This user doesn't...|\n",
      "|5439|Rating|This user doesn't...|\n",
      "|5441|Rating|This user doesn't...|\n",
      "|5443|Rating|This user doesn't...|\n",
      "|5444|Rating|This user doesn't...|\n",
      "|5449|Rating|This user doesn't...|\n",
      "|5453|Rating|This user doesn't...|\n",
      "+----+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "7\n",
      "+----+--------------------+---------------+\n",
      "|  ID|                Name|         Rating|\n",
      "+----+--------------------+---------------+\n",
      "|6675|Baxter, the Pig W...| it was amazing|\n",
      "|6675|Set This House in...|really liked it|\n",
      "|6675|       Paradise Park|really liked it|\n",
      "|7027|       Paradise Park|       liked it|\n",
      "|6675|The Dead Fish Museum| it was amazing|\n",
      "|7360|The Dead Fish Museum|      it was ok|\n",
      "|6675|      Famous Builder|really liked it|\n",
      "|6675|  School of the Arts|really liked it|\n",
      "|8692|  School of the Arts|really liked it|\n",
      "|6675|Butterfly Boy: Me...|       liked it|\n",
      "|7965|Butterfly Boy: Me...| it was amazing|\n",
      "|6675|           Dog Years|really liked it|\n",
      "|9642|           Dog Years|       liked it|\n",
      "|6675|Dahlia Season: St...|really liked it|\n",
      "|6675|     Beyond the Pale|really liked it|\n",
      "|7182|     Beyond the Pale| it was amazing|\n",
      "|6675|No One Belongs He...|really liked it|\n",
      "|6765|No One Belongs He...|really liked it|\n",
      "|6804|No One Belongs He...|really liked it|\n",
      "|7099|No One Belongs He...| it was amazing|\n",
      "+----+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "dfs_r = {}\n",
    "for i in range(len(uno)):\n",
    "        print(num)\n",
    "        ruta_i = ruta_r+'\\\\'+'user_rating_' + str(uno[i]) + '_to_'+str(dos[i])+'.csv'\n",
    "        #print(ruta_i)\n",
    "        name = 'archivo'+'_'+str(i+1)\n",
    "        arch_i = spark.read.csv(ruta_i, \n",
    "                    header=True, \n",
    "                    sep=',', \n",
    "                    quote=\"\\\"\", \n",
    "                    escape=\"\\\"\", \n",
    "                    ignoreTrailingWhiteSpace = True,\n",
    "                    multiLine = True)\n",
    "        num+=1\n",
    "        arch_i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b44eb591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicc_df_r(uno, dos, ruta):\n",
    "    dataframes = dict()\n",
    "    for i in range(len(uno)):\n",
    "        ruta_i = ruta+'\\\\'+'user_rating_' + str(uno[i]) + '_to_'+str(dos[i])+'.csv'\n",
    "        #print(ruta_i)\n",
    "        name = 'archivo'+'_'+str(i+1)\n",
    "        arch_i = spark.read.csv(ruta_i, \n",
    "                    header=True, \n",
    "                    sep=',', \n",
    "                    quote=\"\\\"\", \n",
    "                    escape=\"\\\"\", \n",
    "                    ignoreTrailingWhiteSpace = True,\n",
    "                    multiLine = True)\n",
    "        #print(arch_i.show())\n",
    "        arch_i_pr = cambio_nombre(arch_i, 'ID', 'User_Id')\n",
    "        arch_i_pr = cambio_nombre(arch_i_pr, 'Rating', 'User_Rating')\n",
    "        #print(arch_i_pr.show())\n",
    "        dataframes[name] = arch_i_pr\n",
    "    return dataframes\n",
    "\n",
    "def union_df(dataframes, ar):\n",
    "    i=1\n",
    "    for nombre, dataframe in dataframes.items():\n",
    "        #print(nombre)\n",
    "        if nombre != 'archivo_1':\n",
    "            i+=1\n",
    "            union = ar.union(dataframe)\n",
    "            ar = union\n",
    "    return i, ar\n",
    "\n",
    "def cambio_nombre(df, column, nombre):\n",
    "    from pyspark.sql.functions import col\n",
    "    df = df.withColumn(nombre, col(column))\n",
    "    df = df.drop(col(column))\n",
    "    return df\n",
    "\n",
    "def nombre_ficheros_r():\n",
    "    flag = True\n",
    "    uno = list(range(0,7000,1000))\n",
    "    dos = list(range(1000,7000,1000))\n",
    "    dos.append(11000)\n",
    "    if len(uno) != len(dos): flag = False\n",
    "    return uno, dos, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f584604c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han unido 7 datafames\n",
      "Hay un total de 362596 filas\n"
     ]
    }
   ],
   "source": [
    "pr_r, se_r, flag = nombre_ficheros_r()\n",
    "if flag:\n",
    "    ruta = 'C:\\\\Users\\\\nora.hafidi\\\\Desktop\\\\Big Data\\\\UserRating\\\\archive'\n",
    "    dfs_r = dicc_df_r(pr_r, se_r, ruta)\n",
    "    ar_r = dfs_r['archivo_1']\n",
    "    n, df_r = union_df(dfs_r, ar_r)\n",
    "    print(\"Se han unido \" + str(int(n)) + \" datafames\")\n",
    "    print(\"Hay un total de \"+str(df_r.count())+\" filas\")\n",
    "    \n",
    "else: print('Hay error el los nombres de los ficheros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2202cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+---------------+\n",
      "|                Name|User_Id|    User_Rating|\n",
      "+--------------------+-------+---------------+\n",
      "|Agile Web Develop...|      1| it was amazing|\n",
      "|The Restaurant at...|      1| it was amazing|\n",
      "|          Siddhartha|      1| it was amazing|\n",
      "|The Clock of the ...|      1|really liked it|\n",
      "|Ready Player One ...|      1|really liked it|\n",
      "|The Hunger Games ...|      1| it was amazing|\n",
      "|The Clue in the E...|      1| it was amazing|\n",
      "|The Authoritative...|      1| it was amazing|\n",
      "|The Clue of the B...|      1| it was amazing|\n",
      "|The Clue of the H...|      1| it was amazing|\n",
      "|The Clue of the S...|      1| it was amazing|\n",
      "|The Return of the...|      1| it was amazing|\n",
      "|The Name of the Rose|      1|       liked it|\n",
      "|Blue Mars (Mars T...|      1|       liked it|\n",
      "|Give and Take: A ...|      1| it was amazing|\n",
      "|Mindset: The New ...|      1|really liked it|\n",
      "|Bad Blood: Secret...|      1|really liked it|\n",
      "|Dark Apprentice (...|      1|       liked it|\n",
      "|A Short History o...|      1| it was amazing|\n",
      "|The Mystery of th...|      1| it was amazing|\n",
      "+--------------------+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72b612",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227521b9",
   "metadata": {},
   "source": [
    "### Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca67f65",
   "metadata": {},
   "source": [
    "1. Ordenar los libros de mayor a menor (Top 15) por número de ratings dados por usuarios (excluir aquellos valores sin rating)\n",
    "2. Obtener Top 5 de ratings más frecuentes otorgados por usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e49d17",
   "metadata": {},
   "source": [
    "**1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af05144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                Name|count|\n",
      "+--------------------+-----+\n",
      "|The Catcher in th...|  985|\n",
      "|    The Great Gatsby|  885|\n",
      "|The Da Vinci Code...|  846|\n",
      "|To Kill a Mocking...|  830|\n",
      "|                1984|  756|\n",
      "|     The Kite Runner|  749|\n",
      "|Harry Potter and ...|  728|\n",
      "|         Animal Farm|  717|\n",
      "|Harry Potter and ...|  639|\n",
      "|Harry Potter and ...|  631|\n",
      "|Harry Potter and ...|  595|\n",
      "|Harry Potter and ...|  593|\n",
      "| Pride and Prejudice|  580|\n",
      "| Memoirs of a Geisha|  574|\n",
      "|       The Alchemist|  556|\n",
      "+--------------------+-----+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "(df_r\n",
    "     .where(col(\"Name\")!='Rating')\n",
    "     .groupBy(\"Name\").count()\n",
    "     .orderBy(\"count\", ascending=False)\n",
    "     .show(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e06dbad",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd2e5a",
   "metadata": {},
   "source": [
    "**9.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "689db64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------+\n",
      "|    User_Rating| count|\n",
      "+---------------+------+\n",
      "|really liked it|132808|\n",
      "|       liked it| 96047|\n",
      "| it was amazing| 92354|\n",
      "|      it was ok| 28811|\n",
      "|did not like it|  7811|\n",
      "+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_r\n",
    "     .groupBy(\"User_Rating\").count()\n",
    "     .orderBy(\"count\", ascending=False)\n",
    "     .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eda43c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0922d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2195264d",
   "metadata": {},
   "source": [
    "# Ranking y Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "281b3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_b_r(df1, df2, col, type_join):\n",
    "    df = df1.join(df2, col, type_join)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2555a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_b = join_b_r(df, df_r, 'Name', 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b48e958b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1187955"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r_b.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2980fdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+----------+-----------+--------+-------------------+----------+------------+-----------+------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+-------+---------------+\n",
      "|                Name|    Id|          Authors|      ISBN|pagesNumber|Language|          Publisher|PublishDay|PublishMonth|PublishYear|Rating|RatingDist1|RatingDist2|RatingDist3|RatingDist4|RatingDist5|RatingDistTotal|CountsOfReview|User_Id|    User_Rating|\n",
      "+--------------------+------+-----------------+----------+-----------+--------+-------------------+----------+------------+-----------+------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+-------+---------------+\n",
      "|101 Ways to Use Y...|256773|Elizabeth Dubicki|089689309X|        191|    null|Krause Publications|         1|           7|       2006|  2.79|          5|         13|         24|          8|          2|             52|            17|   4143|did not like it|\n",
      "|14 Minutes: A Run...|  null|             null|      null|       null|    null|               null|      null|        null|       null|  null|       null|       null|       null|       null|       null|           null|          null|   8849|really liked it|\n",
      "|7th Son: Descent ...|  null|             null|      null|       null|    null|               null|      null|        null|       null|  null|       null|       null|       null|       null|       null|           null|          null|   2017|       liked it|\n",
      "|7th Son: Descent ...|  null|             null|      null|       null|    null|               null|      null|        null|       null|  null|       null|       null|       null|       null|       null|           null|          null|  10343|really liked it|\n",
      "|90 Below: Or, Wha...|  null|             null|      null|       null|    null|               null|      null|        null|       null|  null|       null|       null|       null|       null|       null|           null|          null|     18|really liked it|\n",
      "+--------------------+------+-----------------+----------+-----------+--------+-------------------+----------+------------+-----------+------+-----------+-----------+-----------+-----------+-----------+---------------+--------------+-------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r_b.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53893bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1850310 362596\n"
     ]
    }
   ],
   "source": [
    "print(df.count(), df_r.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a667bff",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db52611",
   "metadata": {},
   "source": [
    "## Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32904bd",
   "metadata": {},
   "source": [
    "1. Páginas medias de los 5 libros con más valoraciones dadas por los usuarios\n",
    "2. Idioma que menos gusta a los usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2405d78",
   "metadata": {},
   "source": [
    "**1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b82112fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|    User_Rating|             media|\n",
      "+---------------+------------------+\n",
      "|       liked it| 300.7781731820974|\n",
      "|      it was ok|304.54053772405166|\n",
      "|really liked it| 308.8833428919171|\n",
      "|did not like it| 317.0719956200383|\n",
      "| it was amazing| 321.6364833470025|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "(df_r_b\n",
    "    .where(col(\"pagesNumber\").isNotNull())\n",
    "    .groupBy(\"User_Rating\")\n",
    "    .agg(F.avg(\"pagesNumber\").alias(\"media\"))\n",
    "    .orderBy(\"media\")\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f76c5",
   "metadata": {},
   "source": [
    "**2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c92c5ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Language|count|\n",
      "+--------+-----+\n",
      "|     eng| 9339|\n",
      "+--------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_r_b\n",
    "    .where((col(\"User_Rating\") == 'did not like it') & (col(\"Language\").isNotNull()))\n",
    "    .groupBy(\"Language\").count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    "    .show(1)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
